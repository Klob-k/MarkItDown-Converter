{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# PDF to Markdown Converter\n",
        "## Hybrid Pipeline with Quality Detection & Claude Vision Fallback\n",
        "\n",
        "This notebook converts PDFs to clean, well-structured Markdown using a cost-efficient hybrid approach:\n",
        "\n",
        "1. **MarkItDown** - Fast, free initial extraction\n",
        "2. **Heuristic Quality Checks** - Instant validation of extraction quality\n",
        "3. **Claude Quality Assessment** - AI-powered quality scoring\n",
        "4. **Claude Vision Fallback** - Direct PDF analysis for complex documents\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell1_header"
      },
      "source": [
        "## Cell 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install_deps",
        "outputId": "6781b12c-d26f-4b6a-fc29-bd5db5e0c647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Dependencies installed successfully\n"
          ]
        }
      ],
      "source": [
        "# Install with all optional dependencies\n",
        "!pip install -q 'markitdown[all]' anthropic\n",
        "\n",
        "\n",
        "print(\"✓ Dependencies installed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze1Ga_oFUxyI",
        "outputId": "62644df6-f3a3-4a65-d523-6544152ff8eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ pdfminer.six installed (required for MarkItDown PDF support)\n"
          ]
        }
      ],
      "source": [
        "# Verify PDF dependencies\n",
        "import subprocess\n",
        "result = subprocess.run([\"pip\", \"show\", \"pdfminer.six\"], capture_output=True, text=True)\n",
        "if \"Name: pdfminer.six\" in result.stdout:\n",
        "    print(\"✓ pdfminer.six installed (required for MarkItDown PDF support)\")\n",
        "else:\n",
        "    print(\"✗ pdfminer.six NOT found - installing directly...\")\n",
        "    !pip install -q pdfminer.six\n",
        "    print(\"✓ Installed pdfminer.six\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell2_header"
      },
      "source": [
        "## Cell 2: Configuration & Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "config",
        "outputId": "9fd3baf7-2f30-4a60-d6da-05473c42e674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Configuration loaded\n",
            "  Model: claude-haiku-4-5-20251001\n",
            "  Input: /content/pdfs/Ryder-Investor-Overview-June-2024.pdf\n",
            "  Output: /content/output.md\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import base64\n",
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from google.colab import userdata\n",
        "from anthropic import Anthropic\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "# API Setup\n",
        "ANTHROPIC_API_KEY = userdata.get('Claude_Colab')\n",
        "client = Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "\n",
        "# Model Configuration\n",
        "MODEL = \"claude-haiku-4-5-20251001\"\n",
        "MAX_TOKENS = 8192\n",
        "\n",
        "# Quality Thresholds\n",
        "QUALITY_THRESHOLDS = {\n",
        "    \"min_words_per_page\": 50,      # Minimum words expected per page\n",
        "    \"max_whitespace_ratio\": 0.40,   # Maximum whitespace allowed\n",
        "    \"min_quality_score\": 7,         # Minimum Claude quality score (1-10)\n",
        "    \"min_headers_for_long_doc\": 1,  # Minimum headers for docs > 500 words\n",
        "}\n",
        "\n",
        "# File Paths\n",
        "INPUT_PDF = \"/content/input.pdf\"\"\n",
        "OUTPUT_MD = \"/content/output.md\"\n",
        "\n",
        "# Initialize MarkItDown\n",
        "markitdown = MarkItDown()\n",
        "\n",
        "print(\"✓ Configuration loaded\")\n",
        "print(f\"  Model: {MODEL}\")\n",
        "print(f\"  Input: {INPUT_PDF}\")\n",
        "print(f\"  Output: {OUTPUT_MD}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell3_header"
      },
      "source": [
        "## Cell 3: Quality Assessment Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quality_functions",
        "outputId": "498b54c5-1d81-4ace-8b2f-6d63302088ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Quality assessment functions loaded\n"
          ]
        }
      ],
      "source": [
        "def heuristic_check(markdown: str, page_count: int = 1) -> dict:\n",
        "    \"\"\"\n",
        "    Perform fast, free heuristic checks on extracted markdown.\n",
        "\n",
        "    Returns:\n",
        "        dict: {\"passed\": bool, \"issues\": list, \"metrics\": dict}\n",
        "    \"\"\"\n",
        "    issues = []\n",
        "\n",
        "    # Metric calculations\n",
        "    total_chars = len(markdown)\n",
        "    whitespace_chars = sum(1 for c in markdown if c.isspace())\n",
        "    whitespace_ratio = whitespace_chars / total_chars if total_chars > 0 else 1\n",
        "\n",
        "    words = markdown.split()\n",
        "    word_count = len(words)\n",
        "    words_per_page = word_count / max(page_count, 1)\n",
        "\n",
        "    header_count = len(re.findall(r'^#{1,6}\\s', markdown, re.MULTILINE))\n",
        "\n",
        "    # Check for table integrity (pipes with inconsistent columns)\n",
        "    table_lines = [l for l in markdown.split('\\n') if '|' in l]\n",
        "    table_issues = False\n",
        "    if table_lines:\n",
        "        col_counts = [l.count('|') for l in table_lines]\n",
        "        if col_counts and max(col_counts) - min(col_counts) > 2:\n",
        "            table_issues = True\n",
        "\n",
        "    # Check for repeated character artifacts (OCR noise)\n",
        "    artifact_patterns = [\n",
        "        r'\\.{5,}',      # Multiple dots\n",
        "        r'\\|{3,}',      # Multiple pipes\n",
        "        r'_{5,}',       # Multiple underscores\n",
        "        r'\\s{10,}',     # Excessive whitespace\n",
        "    ]\n",
        "    artifact_count = sum(len(re.findall(p, markdown)) for p in artifact_patterns)\n",
        "\n",
        "    # Evaluate against thresholds\n",
        "    if words_per_page < QUALITY_THRESHOLDS[\"min_words_per_page\"]:\n",
        "        issues.append(f\"Low word count: {words_per_page:.0f} words/page (min: {QUALITY_THRESHOLDS['min_words_per_page']})\")\n",
        "\n",
        "    if whitespace_ratio > QUALITY_THRESHOLDS[\"max_whitespace_ratio\"]:\n",
        "        issues.append(f\"High whitespace ratio: {whitespace_ratio:.1%} (max: {QUALITY_THRESHOLDS['max_whitespace_ratio']:.0%})\")\n",
        "\n",
        "    if word_count > 500 and header_count < QUALITY_THRESHOLDS[\"min_headers_for_long_doc\"]:\n",
        "        issues.append(f\"No headers found in long document ({word_count} words)\")\n",
        "\n",
        "    if table_issues:\n",
        "        issues.append(\"Inconsistent table structure detected\")\n",
        "\n",
        "    if artifact_count > 10:\n",
        "        issues.append(f\"Excessive extraction artifacts detected ({artifact_count} patterns)\")\n",
        "\n",
        "    metrics = {\n",
        "        \"word_count\": word_count,\n",
        "        \"words_per_page\": words_per_page,\n",
        "        \"whitespace_ratio\": whitespace_ratio,\n",
        "        \"header_count\": header_count,\n",
        "        \"artifact_count\": artifact_count,\n",
        "        \"table_line_count\": len(table_lines),\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"passed\": len(issues) == 0,\n",
        "        \"issues\": issues,\n",
        "        \"metrics\": metrics\n",
        "    }\n",
        "\n",
        "\n",
        "def claude_quality_check(markdown: str) -> dict:\n",
        "    \"\"\"\n",
        "    Use Claude to assess the quality of extracted markdown.\n",
        "\n",
        "    Returns:\n",
        "        dict: {\"score\": int, \"issues\": list}\n",
        "    \"\"\"\n",
        "    # Truncate if too long to save tokens\n",
        "    sample = markdown[:8000] if len(markdown) > 8000 else markdown\n",
        "\n",
        "    prompt = f\"\"\"Evaluate this markdown extraction from a PDF. Rate the quality from 1-10 based on:\n",
        "- Completeness (does it appear to capture all content?)\n",
        "- Formatting (are headers, lists, tables properly structured?)\n",
        "- Readability (is it clean and well-organized?)\n",
        "- Artifacts (are there extraction errors, garbled text, or noise?)\n",
        "\n",
        "Respond with ONLY a JSON object, no other text:\n",
        "{{\"score\": N, \"issues\": [\"issue1\", \"issue2\"]}}\n",
        "\n",
        "If there are no issues, return an empty array for issues.\n",
        "\n",
        "---\n",
        "MARKDOWN TO EVALUATE:\n",
        "{sample}\n",
        "---\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.messages.create(\n",
        "            model=MODEL,\n",
        "            max_tokens=500,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "\n",
        "        result_text = response.content[0].text.strip()\n",
        "\n",
        "        # Clean up response if needed\n",
        "        if result_text.startswith('```'):\n",
        "            result_text = re.sub(r'^```json?\\n?', '', result_text)\n",
        "            result_text = re.sub(r'\\n?```$', '', result_text)\n",
        "\n",
        "        result = json.loads(result_text)\n",
        "        return {\n",
        "            \"score\": result.get(\"score\", 0),\n",
        "            \"issues\": result.get(\"issues\", []),\n",
        "            \"tokens_used\": response.usage.input_tokens + response.usage.output_tokens\n",
        "        }\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"  ⚠ Failed to parse quality response: {e}\")\n",
        "        return {\"score\": 0, \"issues\": [\"Failed to parse quality assessment\"], \"tokens_used\": 0}\n",
        "    except Exception as e:\n",
        "        print(f\"  ⚠ Quality check error: {e}\")\n",
        "        return {\"score\": 0, \"issues\": [str(e)], \"tokens_used\": 0}\n",
        "\n",
        "\n",
        "print(\"✓ Quality assessment functions loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell4_header"
      },
      "source": [
        "## Cell 4: Conversion Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "conversion_functions",
        "outputId": "eab0943a-2c3f-48cc-8338-80edc550eb68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Conversion functions loaded\n"
          ]
        }
      ],
      "source": [
        "def markitdown_extract(pdf_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract markdown from PDF using MarkItDown.\n",
        "\n",
        "    Returns:\n",
        "        dict: {\"success\": bool, \"markdown\": str, \"error\": str|None}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = markitdown.convert(pdf_path)\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"markdown\": result.text_content,\n",
        "            \"error\": None\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"markdown\": \"\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "\n",
        "def claude_vision_extract(pdf_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract markdown from PDF using Claude's native PDF/vision capability.\n",
        "\n",
        "    Returns:\n",
        "        dict: {\"success\": bool, \"markdown\": str, \"tokens_used\": int, \"error\": str|None}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read and encode PDF\n",
        "        with open(pdf_path, \"rb\") as f:\n",
        "            pdf_data = base64.standard_b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "        prompt = \"\"\"Convert this PDF to clean, well-structured Markdown. Follow these guidelines:\n",
        "\n",
        "1. **Headers**: Use appropriate header levels (# ## ###) to reflect document hierarchy\n",
        "2. **Tables**: Convert all tables to proper markdown table format\n",
        "3. **Lists**: Use bullet points or numbered lists where appropriate\n",
        "4. **Content**: Preserve ALL text content accurately - do not summarize or omit\n",
        "5. **Charts/Graphics**: Add descriptive placeholders like [Chart: Revenue by Quarter] or [Image: Company Logo]\n",
        "6. **Formatting**: Remove extraction artifacts, fix spacing issues, ensure clean output\n",
        "\n",
        "Output ONLY the markdown content, no explanations or preamble.\"\"\"\n",
        "\n",
        "        response = client.messages.create(\n",
        "            model=MODEL,\n",
        "            max_tokens=MAX_TOKENS,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"document\",\n",
        "                            \"source\": {\n",
        "                                \"type\": \"base64\",\n",
        "                                \"media_type\": \"application/pdf\",\n",
        "                                \"data\": pdf_data\n",
        "                            }\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": prompt\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"markdown\": response.content[0].text,\n",
        "            \"tokens_used\": response.usage.input_tokens + response.usage.output_tokens,\n",
        "            \"error\": None\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"markdown\": \"\",\n",
        "            \"tokens_used\": 0,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "\n",
        "def claude_cleanup(markdown: str) -> dict:\n",
        "    \"\"\"\n",
        "    Clean up and improve MarkItDown output using Claude.\n",
        "\n",
        "    Returns:\n",
        "        dict: {\"success\": bool, \"markdown\": str, \"tokens_used\": int, \"error\": str|None}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        prompt = f\"\"\"Clean up and improve this markdown extracted from a PDF. Your task:\n",
        "\n",
        "1. Fix any formatting inconsistencies (headers, lists, tables)\n",
        "2. Remove extraction artifacts and noise\n",
        "3. Ensure proper markdown table formatting\n",
        "4. Fix spacing and line break issues\n",
        "5. Preserve ALL original content - do not summarize or remove information\n",
        "6. Use consistent header hierarchy\n",
        "\n",
        "Output ONLY the cleaned markdown, no explanations.\n",
        "\n",
        "---\n",
        "MARKDOWN TO CLEAN:\n",
        "{markdown}\n",
        "---\"\"\"\n",
        "\n",
        "        response = client.messages.create(\n",
        "            model=MODEL,\n",
        "            max_tokens=MAX_TOKENS,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"markdown\": response.content[0].text,\n",
        "            \"tokens_used\": response.usage.input_tokens + response.usage.output_tokens,\n",
        "            \"error\": None\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"markdown\": markdown,  # Return original on failure\n",
        "            \"tokens_used\": 0,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "\n",
        "print(\"✓ Conversion functions loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell5_header"
      },
      "source": [
        "## Cell 5: Main Processing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "main_pipeline",
        "outputId": "6709a474-e39a-41b0-9bea-6764320803b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Main pipeline loaded\n"
          ]
        }
      ],
      "source": [
        "def process_pdf(pdf_path: str, verbose: bool = True) -> dict:\n",
        "    \"\"\"\n",
        "    Main processing pipeline with automatic quality detection and fallback.\n",
        "\n",
        "    Args:\n",
        "        pdf_path: Path to the PDF file\n",
        "        verbose: Print progress and diagnostics\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            \"success\": bool,\n",
        "            \"markdown\": str,\n",
        "            \"path_taken\": str,\n",
        "            \"total_tokens\": int,\n",
        "            \"diagnostics\": dict\n",
        "        }\n",
        "    \"\"\"\n",
        "    diagnostics = {\n",
        "        \"markitdown_extraction\": None,\n",
        "        \"heuristic_check\": None,\n",
        "        \"claude_quality_check\": None,\n",
        "        \"final_conversion\": None\n",
        "    }\n",
        "    total_tokens = 0\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Processing: {pdf_path}\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 1: MarkItDown Extraction\n",
        "    # =========================================================================\n",
        "    if verbose:\n",
        "        print(\"[1/4] MarkItDown Extraction...\")\n",
        "\n",
        "    mit_result = markitdown_extract(pdf_path)\n",
        "    diagnostics[\"markitdown_extraction\"] = {\n",
        "        \"success\": mit_result[\"success\"],\n",
        "        \"char_count\": len(mit_result[\"markdown\"]) if mit_result[\"success\"] else 0,\n",
        "        \"error\": mit_result[\"error\"]\n",
        "    }\n",
        "\n",
        "    if not mit_result[\"success\"]:\n",
        "        if verbose:\n",
        "            print(f\"  ✗ MarkItDown failed: {mit_result['error']}\")\n",
        "            print(\"  → Falling back to Claude Vision...\\n\")\n",
        "\n",
        "        # Direct fallback to Claude Vision\n",
        "        vision_result = claude_vision_extract(pdf_path)\n",
        "        total_tokens += vision_result.get(\"tokens_used\", 0)\n",
        "        diagnostics[\"final_conversion\"] = {\n",
        "            \"method\": \"claude_vision_fallback\",\n",
        "            \"reason\": \"markitdown_failed\",\n",
        "            \"tokens\": vision_result.get(\"tokens_used\", 0)\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"success\": vision_result[\"success\"],\n",
        "            \"markdown\": vision_result[\"markdown\"],\n",
        "            \"path_taken\": \"Claude Vision (MarkItDown failed)\",\n",
        "            \"total_tokens\": total_tokens,\n",
        "            \"diagnostics\": diagnostics\n",
        "        }\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  ✓ Extracted {len(mit_result['markdown']):,} characters\\n\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 2: Heuristic Quality Check\n",
        "    # =========================================================================\n",
        "    if verbose:\n",
        "        print(\"[2/4] Heuristic Quality Check...\")\n",
        "\n",
        "    # Estimate page count (rough: ~3000 chars per page)\n",
        "    estimated_pages = max(1, len(mit_result[\"markdown\"]) // 3000)\n",
        "    heuristic_result = heuristic_check(mit_result[\"markdown\"], estimated_pages)\n",
        "    diagnostics[\"heuristic_check\"] = heuristic_result\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  Metrics:\")\n",
        "        for key, value in heuristic_result[\"metrics\"].items():\n",
        "            if isinstance(value, float):\n",
        "                print(f\"    - {key}: {value:.2f}\")\n",
        "            else:\n",
        "                print(f\"    - {key}: {value}\")\n",
        "\n",
        "    if not heuristic_result[\"passed\"]:\n",
        "        if verbose:\n",
        "            print(f\"  ✗ Heuristic check failed:\")\n",
        "            for issue in heuristic_result[\"issues\"]:\n",
        "                print(f\"    - {issue}\")\n",
        "            print(\"  → Falling back to Claude Vision...\\n\")\n",
        "\n",
        "        vision_result = claude_vision_extract(pdf_path)\n",
        "        total_tokens += vision_result.get(\"tokens_used\", 0)\n",
        "        diagnostics[\"final_conversion\"] = {\n",
        "            \"method\": \"claude_vision_fallback\",\n",
        "            \"reason\": \"heuristic_check_failed\",\n",
        "            \"tokens\": vision_result.get(\"tokens_used\", 0)\n",
        "        }\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  {'✓' if vision_result['success'] else '✗'} Claude Vision: {vision_result.get('tokens_used', 0):,} tokens\\n\")\n",
        "\n",
        "        return {\n",
        "            \"success\": vision_result[\"success\"],\n",
        "            \"markdown\": vision_result[\"markdown\"],\n",
        "            \"path_taken\": \"Claude Vision (Heuristic failed)\",\n",
        "            \"total_tokens\": total_tokens,\n",
        "            \"diagnostics\": diagnostics\n",
        "        }\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  ✓ Heuristic check passed\\n\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 3: Claude Quality Assessment\n",
        "    # =========================================================================\n",
        "    if verbose:\n",
        "        print(\"[3/4] Claude Quality Assessment...\")\n",
        "\n",
        "    quality_result = claude_quality_check(mit_result[\"markdown\"])\n",
        "    total_tokens += quality_result.get(\"tokens_used\", 0)\n",
        "    diagnostics[\"claude_quality_check\"] = quality_result\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  Score: {quality_result['score']}/10\")\n",
        "        if quality_result[\"issues\"]:\n",
        "            print(f\"  Issues:\")\n",
        "            for issue in quality_result[\"issues\"]:\n",
        "                print(f\"    - {issue}\")\n",
        "        print(f\"  Tokens used: {quality_result.get('tokens_used', 0):,}\\n\")\n",
        "\n",
        "    if quality_result[\"score\"] < QUALITY_THRESHOLDS[\"min_quality_score\"]:\n",
        "        if verbose:\n",
        "            print(f\"  ✗ Quality score below threshold ({QUALITY_THRESHOLDS['min_quality_score']})\")\n",
        "            print(\"  → Falling back to Claude Vision...\\n\")\n",
        "\n",
        "        vision_result = claude_vision_extract(pdf_path)\n",
        "        total_tokens += vision_result.get(\"tokens_used\", 0)\n",
        "        diagnostics[\"final_conversion\"] = {\n",
        "            \"method\": \"claude_vision_fallback\",\n",
        "            \"reason\": f\"quality_score_{quality_result['score']}_below_{QUALITY_THRESHOLDS['min_quality_score']}\",\n",
        "            \"tokens\": vision_result.get(\"tokens_used\", 0)\n",
        "        }\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  {'✓' if vision_result['success'] else '✗'} Claude Vision: {vision_result.get('tokens_used', 0):,} tokens\\n\")\n",
        "\n",
        "        return {\n",
        "            \"success\": vision_result[\"success\"],\n",
        "            \"markdown\": vision_result[\"markdown\"],\n",
        "            \"path_taken\": f\"Claude Vision (Quality score: {quality_result['score']}/10)\",\n",
        "            \"total_tokens\": total_tokens,\n",
        "            \"diagnostics\": diagnostics\n",
        "        }\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  ✓ Quality check passed\\n\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 4: Claude Cleanup\n",
        "    # =========================================================================\n",
        "    if verbose:\n",
        "        print(\"[4/4] Claude Cleanup...\")\n",
        "\n",
        "    cleanup_result = claude_cleanup(mit_result[\"markdown\"])\n",
        "    total_tokens += cleanup_result.get(\"tokens_used\", 0)\n",
        "    diagnostics[\"final_conversion\"] = {\n",
        "        \"method\": \"markitdown_plus_cleanup\",\n",
        "        \"reason\": \"quality_check_passed\",\n",
        "        \"tokens\": cleanup_result.get(\"tokens_used\", 0)\n",
        "    }\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  {'✓' if cleanup_result['success'] else '✗'} Cleanup complete: {cleanup_result.get('tokens_used', 0):,} tokens\\n\")\n",
        "\n",
        "    return {\n",
        "        \"success\": cleanup_result[\"success\"],\n",
        "        \"markdown\": cleanup_result[\"markdown\"],\n",
        "        \"path_taken\": \"MarkItDown + Claude Cleanup\",\n",
        "        \"total_tokens\": total_tokens,\n",
        "        \"diagnostics\": diagnostics\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"✓ Main pipeline loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell6_header"
      },
      "source": [
        "## Cell 6: Execute Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "execute",
        "outputId": "9cdb61aa-1f4f-4950-bc8d-4f2f19dc5434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Processing: /content/pdfs/Ryder-Investor-Overview-June-2024.pdf\n",
            "============================================================\n",
            "\n",
            "[1/4] MarkItDown Extraction...\n",
            "  ✓ Extracted 25,632 characters\n",
            "\n",
            "[2/4] Heuristic Quality Check...\n",
            "  Metrics:\n",
            "    - word_count: 3688\n",
            "    - words_per_page: 461.00\n",
            "    - whitespace_ratio: 0.17\n",
            "    - header_count: 0\n",
            "    - artifact_count: 4\n",
            "    - table_line_count: 0\n",
            "  ✗ Heuristic check failed:\n",
            "    - No headers found in long document (3688 words)\n",
            "  → Falling back to Claude Vision...\n",
            "\n",
            "  ✓ Claude Vision: 49,046 tokens\n",
            "\n",
            "============================================================\n",
            "SUMMARY\n",
            "============================================================\n",
            "Status: ✓ Success\n",
            "Path taken: Claude Vision (Heuristic failed)\n",
            "Total tokens used: 49,046\n",
            "Output length: 27,500 characters\n",
            "\n",
            "✓ Saved to: /content/output.md\n",
            "\n",
            "============================================================\n",
            "PREVIEW (first 2000 characters)\n",
            "============================================================\n",
            "\n",
            "# Investor Overview\n",
            "## June 2024\n",
            "\n",
            "![Ryder Logo](ryder-logo.png)\n",
            "\n",
            "![Fleet and Operations Image](ryder-operations.png)\n",
            "\n",
            "---\n",
            "\n",
            "## Safe Harbor and Non-GAAP Financial Measures\n",
            "\n",
            "### Note Regarding Forward-Looking Statements\n",
            "\n",
            "Certain statements and information included in this news release are \"forward-looking statements\" under the Federal Private Securities Litigation Reform Act of 1995, including:\n",
            "\n",
            "- Our forecast and outlook\n",
            "- Our expectations regarding market trends and economic environment, such as:\n",
            "  - Rental demand\n",
            "  - Economic growth\n",
            "  - Challenging freight environment\n",
            "  - Weakening used vehicle sales and rental\n",
            "  - Declining volumes in our omnichannel retail vertical\n",
            "- Our expectations regarding the freight cycle, including timing and impact on our businesses\n",
            "- Our expectations regarding total and operating revenue, earnings per share, comparable earnings per share, adjusted ROE, earnings before income tax, net cash from operating activities from continuing operations, debt-to-equity, capital expenditures, operating cash flow, free cash flow\n",
            "- Our ability to execute our balanced growth strategy\n",
            "- The impact of inflationary pressures and inflationary cost recovery\n",
            "- Our expectations regarding commercial rental demand and utilization and used vehicle sales volume and pricing\n",
            "- Our expectations with respect to ChoiceLease growth\n",
            "- Our expectations with respect to the timing of OEM deliveries and vehicle production\n",
            "- Our expectations with respect to our actions to increase returns and create long-term value\n",
            "- Our ability to outperform prior cycles\n",
            "- Our expectations regarding long-term profitable growth and secular growth trends\n",
            "- Our ability to profitably grow SCS/DTS\n",
            "- Benefits from FMS lease pricing and maintenance cost savings initiatives\n",
            "- Our expectations regarding used vehicle inventory and fleet size\n",
            "- Our ability to redeploy rental vehicles and leverage our expanded retail used vehicle network\n",
            "- Our ability to execute our enhanced asset management playbook\n",
            "- Ou\n",
            "\n",
            "... [25,500 more characters]\n"
          ]
        }
      ],
      "source": [
        "# Check if input file exists\n",
        "if not Path(INPUT_PDF).exists():\n",
        "    print(f\"❌ Error: Input file not found: {INPUT_PDF}\")\n",
        "    print(\"\\nPlease upload your PDF to /content/ or update INPUT_PDF path in Cell 2.\")\n",
        "else:\n",
        "    # Process the PDF\n",
        "    result = process_pdf(INPUT_PDF, verbose=True)\n",
        "\n",
        "    # Summary\n",
        "    print(f\"{'='*60}\")\n",
        "    print(\"SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Status: {'✓ Success' if result['success'] else '✗ Failed'}\")\n",
        "    print(f\"Path taken: {result['path_taken']}\")\n",
        "    print(f\"Total tokens used: {result['total_tokens']:,}\")\n",
        "    print(f\"Output length: {len(result['markdown']):,} characters\")\n",
        "\n",
        "    if result[\"success\"]:\n",
        "        # Save output\n",
        "        with open(OUTPUT_MD, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(result[\"markdown\"])\n",
        "        print(f\"\\n✓ Saved to: {OUTPUT_MD}\")\n",
        "\n",
        "        # Preview\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"PREVIEW (first 2000 characters)\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "        print(result[\"markdown\"][:2000])\n",
        "        if len(result[\"markdown\"]) > 2000:\n",
        "            print(f\"\\n... [{len(result['markdown']) - 2000:,} more characters]\")\n",
        "    else:\n",
        "        print(f\"\\n❌ Conversion failed. Check diagnostics above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell7_header"
      },
      "source": [
        "## Cell 7: Batch Processing (Optional)\n",
        "\n",
        "Use this cell to process multiple PDFs in a directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "batch_processing"
      },
      "outputs": [],
      "source": [
        "def batch_process(input_dir: str, output_dir: str, verbose: bool = False) -> list:\n",
        "    \"\"\"\n",
        "    Process all PDFs in a directory.\n",
        "\n",
        "    Args:\n",
        "        input_dir: Directory containing PDF files\n",
        "        output_dir: Directory to save markdown files\n",
        "        verbose: Print detailed progress for each file\n",
        "\n",
        "    Returns:\n",
        "        list: Results for each processed file\n",
        "    \"\"\"\n",
        "    input_path = Path(input_dir)\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    pdf_files = list(input_path.glob(\"*.pdf\")) + list(input_path.glob(\"*.PDF\"))\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(f\"No PDF files found in {input_dir}\")\n",
        "        return []\n",
        "\n",
        "    print(f\"Found {len(pdf_files)} PDF files to process\\n\")\n",
        "\n",
        "    results = []\n",
        "    total_tokens = 0\n",
        "\n",
        "    for i, pdf_file in enumerate(pdf_files, 1):\n",
        "        print(f\"[{i}/{len(pdf_files)}] {pdf_file.name}...\", end=\" \")\n",
        "\n",
        "        result = process_pdf(str(pdf_file), verbose=verbose)\n",
        "        result[\"filename\"] = pdf_file.name\n",
        "        results.append(result)\n",
        "        total_tokens += result[\"total_tokens\"]\n",
        "\n",
        "        if result[\"success\"]:\n",
        "            output_file = output_path / f\"{pdf_file.stem}.md\"\n",
        "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(result[\"markdown\"])\n",
        "            print(f\"✓ ({result['total_tokens']:,} tokens)\")\n",
        "        else:\n",
        "            print(f\"✗ Failed\")\n",
        "\n",
        "    # Summary\n",
        "    successful = sum(1 for r in results if r[\"success\"])\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"BATCH SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Processed: {len(pdf_files)} files\")\n",
        "    print(f\"Successful: {successful}\")\n",
        "    print(f\"Failed: {len(pdf_files) - successful}\")\n",
        "    print(f\"Total tokens: {total_tokens:,}\")\n",
        "    print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Example usage (uncomment to run):\n",
        "# batch_results = batch_process(\"/content/pdfs\", \"/content/markdown_output\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell8_header"
      },
      "source": [
        "## Cell 8: Diagnostics & Debugging (Optional)\n",
        "\n",
        "Use this cell to inspect detailed diagnostics from the last run."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display full diagnostics from last run\n",
        "if 'result' in dir() and result is not None:\n",
        "    print(\"Full Diagnostics:\")\n",
        "    print(json.dumps(result[\"diagnostics\"], indent=2))\n",
        "else:\n",
        "    print(\"No results available. Run Cell 6 first.\")\n",
        ""
      ],
      "metadata": {
        "id": "oT6Bx4a5mNQQ",
        "outputId": "b3f256c1-810d-4103-ef3b-3429a82f6cbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Diagnostics:\n",
            "{\n",
            "  \"markitdown_extraction\": {\n",
            "    \"success\": true,\n",
            "    \"char_count\": 25632,\n",
            "    \"error\": null\n",
            "  },\n",
            "  \"heuristic_check\": {\n",
            "    \"passed\": false,\n",
            "    \"issues\": [\n",
            "      \"No headers found in long document (3688 words)\"\n",
            "    ],\n",
            "    \"metrics\": {\n",
            "      \"word_count\": 3688,\n",
            "      \"words_per_page\": 461.0,\n",
            "      \"whitespace_ratio\": 0.16604244694132334,\n",
            "      \"header_count\": 0,\n",
            "      \"artifact_count\": 4,\n",
            "      \"table_line_count\": 0\n",
            "    }\n",
            "  },\n",
            "  \"claude_quality_check\": null,\n",
            "  \"final_conversion\": {\n",
            "    \"method\": \"claude_vision_fallback\",\n",
            "    \"reason\": \"heuristic_check_failed\",\n",
            "    \"tokens\": 49046\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}